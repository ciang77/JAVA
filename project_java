1.	设计并实现基于Redis ZSet与Lua脚本的用户会话控制机制，限制单用户最多同时在线N个终端，自动淘汰最早的token，有效防止token滥用和系统资源过载，提升系统稳定性与安全性。
在这个功能里，Lua 脚本的角色就是：会话控制逻辑的“原子化执行单元”：在 Redis 内部一次性完成会话数检查 → 旧 token 淘汰 → 新 token 添加，避免并发冲突，减少网络延迟，提升性能和安全性。
注意：redis和lua脚本结合可能会出现脚本注入问题，在 Redis 里用 Lua，安全性取决于你是否把用户输入当作代码执行。只要所有用户数据都通过 KEYS / ARGV 参数传入，就不会有脚本注入的风险。


2.	负责引入 TransmittableThreadLocal（TTL）并实现上下文传递机制，将请求头中的用户信息缓存至线程变量中，支持在异步线程/线程池环境中安全传递用户上下文，减少重复数据库查询，提高系统性能与上下文访问效率。

ThreadLocal 是什么？
ThreadLocal 是Java中 lang 包下的一个类，是用来解决多线程下共享变量并发问题的，所谓共享变量即同一个变量在不同线程下赋予不同值。
ThreadLocal 会在多线程环境中为每个线程维护独立的变量副本，让每个线程都拥有自己的数据副本，避免了多个线程同时访问同一个变量的冲突问题。

你刚说到 ThreadLocal，能说下他的内部结构吗？
在 ThreadLocal 中每一个thread维护一个threadlocalmap，threadlocalmap是由threadlocal维护的，map里面存的key是threadlocal对象本身，value是变量副本，主要有set方法和get方法。

threadlocalmap 基本结构清楚吗？
threadlocalmap 是threadlocal静态内部类，key是threadlocal对象是弱引用，目的是将threadlocal对象的生命周期和线程的生命周期解绑

内存泄漏指的是什么？他和内存溢出有什么区别？
内存泄漏是指无用对象无法被GC回收，始终占用内存，造成空间浪费，最终会导致内存溢出，内存溢出指的是程序申请内存，没有足够的空间供其使用，out of memory。

OK，那你清楚 threadlocal 出现内存泄漏的真实原因是什么吗？
一、没有手动删除Entry对象，使用完threadlocal调用其remove方法就可以删除对应的Entry，避免内存泄漏；
二、threadlocal的使用，thread也随之结束
根本原因：threadlocalmap和thread生命周期是一样的。


你能详细解释一下什么是 TTL 吗？它与标准的 ThreadLocal 有什么不同？
TTL 是一种增强版的 ThreadLocal，主要用于解决在使用线程池等多线程框架时，无法传递父子线程之间上下文信息的问题。与标准的 ThreadLocal 不同，TTL 可以在新创建的子线程中，继承父线程的 ThreadLocal 变量。

你能具体描述一下使用 TTL 缓存用户数据的实现步骤吗？
用户登录之后会返回 token，之后的请求将会带上这个 token，当然 token 中会携带有用户的信息，所有请求最先经过网关的过滤器 AuthFilter，在过滤器中用户信息放到请求头，
所有请求经过网关后会来到自定义请求头拦截器 HeaderInterceptor，在拦截器中拿出请求头中的用户信息放到 TTL 中，这样链路上的服务就可以直接从 TTL 中取出用户信息了。


在你们的项目中，是否有遇到过 TTL 导致的内存泄漏问题？如果有，是如何解决的？
是的，我们确实遇到过一次由于 TTL 使用不当导致的内存泄漏问题。原因是某些长时间运行的线程没有及时清理其持有的 ThreadLocal 变量。为了解决这个问题，我们在每次请求完成完成后，确保清理相关的 ThreadLocal 变量，
在 HeaderInterceptor 中的 afterCompletion 方法会清理掉。另外还增加了定期检查和清理机制，以防止内存泄漏。

你们在使用 TTL 时，有没有遇到过并发问题？如果有，是如何处理的？
在使用 TTL 时，由于每个线程都有独立的 ThreadLocal 变量实例，因此一般不会出现并发问题。但我们确实遇到过在高并发场景下，TTL 的值被错误修改的情况。为了解决这个问题，我们在关键代码段增加了同步机制，
并使用了线程安全的集合来存储共享数据，从而避免了并发修改的问题。

3.	针对系统同步写入导致的性能瓶颈和高延迟问题，设计并实现了基于 RocketMQ 的异步削峰架构，将设备高频上报数据高效汇聚至消息队列。通过优化连接池与阻塞队列机制，成功将系统写入延迟从数百毫秒缩减至 80ms 以内，
显著提升了系统的吞吐能力和稳定性。

在项目中，我们遇到设备高频上报数据导致同步写入瓶颈和高延迟的问题，写入延迟一度达到数百毫秒，影响系统吞吐量与稳定性。
为此，我设计并实现了基于 RocketMQ 的异步削峰架构：

生产端：设备数据上报后，由业务服务作为生产者将数据异步发送至 RocketMQ 主题，避免阻塞主线程；
消息队列：RocketMQ 作为缓冲层，将高并发瞬时流量平滑化；
消费端：独立的消费服务从 MQ 批量拉取消息，结合批量写入策略和多线程处理，显著减少单次 I/O 开销；
链路优化：针对数据库写入，调优连接池参数（最大连接数、空闲连接数、等待时间等），并优化阻塞队列容量与批量取数策略，防止数据积压和资源浪费。
最终将系统的写入延迟从数百毫秒缩短至80ms 以内，在高并发场景下显著提升了系统的吞吐能力和稳定性。

我们的延迟测试主要分两步：
首先在生产者发送消息时记录时间戳，在消费者写入完成后再次记录时间戳，计算端到端的真实延迟；其次通过日志打点和链路追踪，将延迟拆分为发送耗时、队列等待时间和消费处理耗时，精准定位瓶颈。
压测阶段我们使用 JMeter 模拟高并发设备上报，在相同并发条件下，对比优化前后延迟分布，最终验证写入延迟由数百毫秒降到 80ms 以内。


4.	使用Redis有序集合管理设备能耗数据的时间序列，实现毫秒级排序与区间聚合分析；结合本地缓存和批量数据拉取技术，优化接口数据访问路径，将接口响应时间从 180ms 降至 35ms，大幅提升系统查询效率和用户体验。

Redis 有序集合（ZSet）管理时间序列：ZSet 的 score 存储时间戳（毫秒级），value 存储能耗数据 JSON 或 ID。
使用 Redis 的 ZRANGEBYSCORE 获取指定时间范围数据：聚合逻辑（如求和、平均值、最大值等）在应用层批量计算，或用 Lua 脚本在 Redis 端一次完成：
本地缓存 + 批量数据拉取：热门查询结果直接缓存在应用内存中，TTL 几秒到几十秒。避免重复访问 Redis。
批量拉取：一次请求中批量取出区间内数据，而不是多次单点查询。尽量减少 Redis 网络往返次数（RTT）


5.	负责设计并实现Nacos配置持久化方案，将配置数据存储至数据库，确保在 Nacos 服务重启时配置不丢失，提升系统配置的高可用性和稳定性。

默认情况下，Nacos 的配置数据主要存在内存或本地文件，服务重启可能导致配置丢失。这对生产环境配置管理风险较大，影响系统稳定性和可用性
针对 Nacos 配置可能因服务重启而丢失的问题，我设计并实现了基于关系型数据库的配置持久化方案。具体做法是将配置数据存储在 MySQL 数据库中，配置更新时同步写入数据库，服务启动时从数据库加载全部配置到缓存。
通过数据库的主从复制和 Nacos 集群模式，保证配置的高可用性和一致性。该方案有效防止了配置丢失问题，提升了系统整体的稳定性和可靠性。

写入时，我在配置变更接口中实现数据库持久化操作，先查询是否已有配置记录，有则更新，无则新增。写库操作通过事务管理保证一致性。写库成功后，立即更新内存缓存，保证后续读取命中缓存，提升访问性能。
这样实现了配置数据的同步持久化和缓存双写，确保服务重启时配置不会丢失。




项目2：
1.	自主设计并实现 Spring Cloud Gateway 全局过滤器，完成微服务网关的统一鉴权功能，重点在于 JWT 令牌的精准校验和解析其中的角色与权限信息，实现基于角色的:细粒度接口访问控制；
同时参与接口调用耗时统计模块的优化，提升了系统异常快速定位效率和运维便捷性，保障了平台的安全稳定运行。

你是如何编写SpringCloud Gateway全局过滤器的？
在 PmHub 项目中，我在网关服务中新建了一个过滤器类 AuthFilter ，实现了 Gateway 的 GlobalFilter 接口，并自定义了 filter 方法实现，包括：
白名单过滤，过滤掉不需要验证的请求路径
进行 token 鉴权，比如说令牌不能为空、不能过期等，然后把用户信息放在了请求头，方便服务调用传递
最后，还记录了访问接口的开始时间，方便统计接口调用的耗时情况
另外，AuthFilter 还实现了 Spring 的 Ordered 接口，以提高这个类在 Spring 容器中的加载顺序。

JWT（JSON Web Token）鉴权流程其实挺直观，主要用于无状态的用户身份验证。简单来说，JWT 是一种自包含的令牌，服务端签发给客户端，客户端携带它去请求，服务端验证它的合法性来判断身份。
如何提升 JWT 安全性？
使用 HTTPS 全站加密传输。
密钥管理 做好密钥保护和定期更换。
合理设置过期时间，避免长期有效。
避免在 Payload 里放敏感信息。
实现 Token 黑名单或刷新机制，保证能撤销失效的 Token。
使用成熟库和框架，避免手写底层逻辑。
限制 Token 权限范围，最小权限原则。

2.	在作战指挥系统中负责项目与任务审批流相关功能的优化改造，采用 RocketMQ 实现关键业务消息的异步处理与系统间解耦，有效提升系统响应效率与服务稳定性；同时参与导出报告功能的开发与维护，
针对格式不规范等问题进行代码修复与样式优化，确保导出内容符合业务需求与用户展示标准。

在作战指挥系统中，我参与了项目与任务审批流的优化改造，采用 RocketMQ 实现关键业务消息的异步处理。通过将审批状态变更等操作异步发送到消息队列，解耦系统间调用，显著提升了系统的响应效率和稳定性。
同时，我参与导出报告功能的开发与维护，针对格式不规范的问题进行了代码修复与样式优化，确保导出文件符合业务需求和用户展示标准，提高了用户体验和维护效率。

3.	参与军工内网科研管理平台跨域集成方案，协助深度分析并优化 Nginx 安全配置，突破严格 X-Frame-Options 限制，实现高安全等级下的可信外部页面嵌入，保障系统安全与访问稳定性。


军工内网科研管理平台往往有多个系统（不同子域、甚至不同网段），为了提高效率，需要在一个门户或主平台中嵌入外部子系统页面。
受控反向代理（Nginx）
在门户系统侧，通过 Nginx 配置反向代理，把外部子系统的地址“代理”到门户域名下。
外部系统对浏览器而言就是“同域”，从而绕过 X-Frame-Options: SAMEORIGIN 限制。

可信白名单控制
在 Nginx 层配置 IP 白名单，仅允许内网网段访问。
在后端逻辑层加上权限校验（JWT/单点登录），保证只有经过认证的用户才能访问子系统。

优化安全配置
X-Frame-Options：由 Nginx 清理掉下游响应头，统一由门户设置允许策略。
Content-Security-Policy (CSP)：通过 frame-ancestors 精确控制哪些页面可以嵌入（只允许门户）。
Referrer-Policy：避免跨域时泄露内部 URL 信息。
Strict-Transport-Security (HSTS)：保证强制 HTTPS，避免中间人攻击。

嵌入实现
门户系统的前端 <iframe src="/subsys/"> 直接加载受控代理后的地址。
用户无感知，但实际走的是门户的 Nginx 反向代理层。

4.	针对内网环境下源数据接口首次调用慢的问题，引入CompletableFuture并行化请求多个模板字段，将接口响应时间从1秒以上优化至 0.3秒。

利用 Java 的 CompletableFuture，对多个模板字段的请求进行异步并行处理。并行发起请求，等待全部完成后再汇总结果返回。减少等待时间，显著提升响应速度。
同时，我配置了专用线程池和超时控制，确保并发量受控且具备容错能力。最终将接口响应时间从1秒以上优化至0.3秒，大幅提升了系统性能和用户体验。

项目3：
1、RAG 检索流程
“在智能问数中，我们通过 RAG（Retrieval-Augmented Generation）构建了私有知识问答体系。具体做法是：用户提出问题后，我们先用企业内部知识库进行向量检索和语义召回，找到最相关的片段，然后把这些片段和用户问题拼接成增强型 Prompt，
传给大模型生成回答。这样做的优势是：一方面保证了问答的准确性和可控性，另一方面能够利用企业私有知识，同时减少模型 hallucination。我们还结合了 BM25 和语义检索的双引擎策略，既保证语义匹配，又保证关键词精确命中。”

2、Kafka 异步文档处理流水线
“为了支持大规模企业文档处理，我们设计了基于 Kafka 的异步流水线。文件上传时只负责接收并生成消息，后台消费者异步解析文件内容并向量化，再索引到 Elasticsearch。
这个设计的好处是解耦上传和处理流程，避免阻塞用户请求，提高吞吐量。例如，我们测试过 500MB 文件上传只需约 200 毫秒，保证系统高性能处理大文件。”

3、Redis 多轮对话历史管理
“在问数场景中，用户可能会有多轮追问。为此，我们在 Redis 中为每个用户分配唯一会话 ID，按时间顺序存储每轮对话，设置 7 天过期时间，同时启用持久化机制。
这样可以保证用户中断后仍能恢复上下文信息，让模型在多轮问答中保持连续性。我们还限制每会话的消息条数，防止 Redis 内存占用过大。”

4、SSE + LLM 流式输出
“为了提升用户交互体验，我们在后端使用 SSE（Server-Sent Events）结合大模型的 Stream API，实现智能问数的流式输出。用户在前端看到的是逐字返回的结果，而不是等待完整回答生成后一次性返回。
这样做首响应时间从原来的 2.3 秒降到了 0.6 秒，显著改善了用户体验，尤其是对于长文本生成场景非常友好。”

5、Elasticsearch + IK 分词 + 向量检索

“企业知识库文档包括 Word、PDF、TXT 等多种格式，我们先解析成文本，然后用 IK 分词器建立倒排索引，同时使用豆包 Embedding 模型生成 2048 维向量。
检索时结合 KNN 向量召回和关键词过滤，再用 BM25 重排序，实现‘关键词 + 语义’双引擎搜索。
这种方法既保证了语义相关性，又保证了关键词精度，提高了检索准确率和召回率。”








