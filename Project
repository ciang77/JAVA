1、Gateway实现全局过滤器以及进行接口调用耗时统计

你是如何编写SpringCloud Gateway全局过滤器的？
在 PmHub 项目中，我在网关服务中新建了一个过滤器类 AuthFilter ，实现了 Gateway 的 GlobalFilter 接口，并自定义了 filter 方法实现，包括：
白名单过滤，过滤掉不需要验证的请求路径
进行 token 鉴权，比如说令牌不能为空、不能过期等，然后把用户信息放在了请求头，方便服务调用传递
最后，还记录了访问接口的开始时间，方便统计接口调用的耗时情况
另外，AuthFilter 还实现了 Spring 的 Ordered 接口，以提高这个类在 Spring 容器中的加载顺序。


什么是网关，网关在微服务架构中的作用是什么？
网关充当了微服务请求的入口，主要负责请求转发、负载均衡、权限校验、日志记录等功能。


有 Nginx 了为什么还要 SpringCloud Gateway 做网关，两者有啥区别？
Nginx 属于前置网关，擅长处理静态资源、SSL 加密和简单的流量管理，但不支持动态路由决策和复杂的业务逻辑。
Spring Cloud Gateway 是专门为微服务架构设计的，更加贴近业务逻辑，支持动态路由、复杂的过滤器、鉴权、限流等。
在生产环境中，通常会把两者结合起来，Nginx 用来处理静态资源和高并发流量，Spring Cloud Gateway 用来实现动态路由、权限校验和业务逻辑处理。


在自定义网关鉴权过程中，你遇到了哪些挑战？你是如何解决的？
一开始，我把网关的配置信息都放到了配置文件中，这样就没办法在线更新，于是后来我就通过 Nacos 把配置信息持久化到了 MySQL 当中，这样当我需要调整过滤器的白名单啊、路由规则啊，就可以直接通过 Nacos 的配置管理中心实时进行修改。


2、整合TransmittableThreadLocal (TTL)缓存用户数据

ThreadLocal 是什么？
ThreadLocal 是Java中 lang 包下的一个类，是用来解决多线程下共享变量并发问题的，所谓共享变量即同一个变量在不同线程下赋予不同值。
ThreadLocal 会在多线程环境中为每个线程维护独立的变量副本，让每个线程都拥有自己的数据副本，避免了多个线程同时访问同一个变量的冲突问题。


ThreadLocal和 synchronized 区别？
ThreadLocal 用于每个线程独享一份变量副本，解决线程间数据隔离问题；
synchronized 用于多个线程共享资源时的同步控制，解决线程安全问题。
synchronized 是基于锁机制的，用于控制对共享资源的访问，确保线程间数据的一致性和安全性，实现线程间的互斥访问
所以说， synchronized是时间换空间让多个线程排队访问，ThreadLocal是空间换时间为每个线程提供了一份变量的副本，从而实现线程隔离。


你刚说到 ThreadLocal，能说下他的内部结构吗？
在 ThreadLocal 中每一个thread维护一个threadlocalmap，threadlocalmap是由threadlocal维护的，map里面存的key是threadlocal对象本身，value是变量副本，主要有set方法和get方法。

threadlocalmap 基本结构清楚吗？
threadlocalmap 是threadlocal静态内部类，key是threadlocal对象是弱引用，目的是将threadlocal对象的生命周期和线程的生命周期解绑

你说 threadlocalmap 中的 key 使用了弱引用，那这会可能造成什么问题？
threadlocalmap 中的 key 使用了弱引用，可能造成内存泄漏

内存泄漏指的是什么？他和内存溢出有什么区别？
内存泄漏是指无用对象无法被GC回收，始终占用内存，造成空间浪费，最终会导致内存溢出，内存溢出指的是程序申请内存，没有足够的空间供其使用，out of memory。

OK，那你清楚 threadlocal 出现内存泄漏的真实原因是什么吗？
一、没有手动删除Entry对象，使用完threadlocal调用其remove方法就可以删除对应的Entry，避免内存泄漏；
二、threadlocal的使用，thread也随之结束
根本原因：threadlocalmap和thread生命周期是一样的。

OK，你直到threadlocalMap 是如何来解决 hash 冲突的？
如果hash冲突，数组下标加1，如果还是冲突依次计算直到超过数组下标，这个时候又重头开始，相当于一个环形数组

你能详细解释一下什么是 TTL 吗？它与标准的 ThreadLocal 有什么不同？
TTL 是一种增强版的 ThreadLocal，主要用于解决在使用线程池等多线程框架时，无法传递父子线程之间上下文信息的问题。与标准的 ThreadLocal 不同，TTL 可以在新创建的子线程中，继承父线程的 ThreadLocal 变量。

你能具体描述一下使用 TTL 缓存用户数据的实现步骤吗？
用户登录之后会返回 token，之后的请求将会带上这个 token，当然 token 中会携带有用户的信息，所有请求最先经过网关的过滤器 AuthFilter，在过滤器中用户信息放到请求头，
所有请求经过网关后会来到自定义请求头拦截器 HeaderInterceptor，在拦截器中拿出请求头中的用户信息放到 TTL 中，这样链路上的服务就可以直接从 TTL 中取出用户信息了。


在你们的项目中，是否有遇到过 TTL 导致的内存泄漏问题？如果有，是如何解决的？
是的，我们确实遇到过一次由于 TTL 使用不当导致的内存泄漏问题。原因是某些长时间运行的线程没有及时清理其持有的 ThreadLocal 变量。为了解决这个问题，我们在每次请求完成完成后，确保清理相关的 ThreadLocal 变量，在 HeaderInterceptor 中的 afterCompletion 方法会清理掉。另外还增加了定期检查和清理机制，以防止内存泄漏。

你们在使用 TTL 时，有没有遇到过并发问题？如果有，是如何处理的？
在使用 TTL 时，由于每个线程都有独立的 ThreadLocal 变量实例，因此一般不会出现并发问题。但我们确实遇到过在高并发场景下，TTL 的值被错误修改的情况。为了解决这个问题，我们在关键代码段增加了同步机制，并使用了线程安全的集合来存储共享数据，从而避免了并发修改的问题。


3、集成Redission分布式锁保障流程状态更新
synchronized锁是Java提供的一种内置锁，在单个JVM进程中提供线程之间的锁定机制，控制多线程并发。只适用于单机环境下的并发控制。

但是在分布式系统中，如果想要锁定多个节点服务，synchronized就不适用于了，会带来数据不一致的问题：比如服务 A 获取数据后，更新缓存 key = 100，服务 B 不受服务 A 的锁限制，并发去更新缓存 key = 99，最后的结果可能是 99 或 100，但这是一种未知的状态，与期望结果不一致。

想要在多个节点中提供锁定，在分布式系统并发控制共享资源，确保同一时刻只有一个访问可以调用，避免多个调用者竞争调用和数据不一致问题，保证数据的一致性，就可以利用分布式锁，分布式锁就是控制分布式系统不同进程访问共享资源的一种锁的机制。不同进程之间调用需要保持互斥性，任意时刻，只有一个客户端能持有锁。

分布式锁的特性：互斥性、超时机制、自动续期

互斥性
分布式锁最基本的特性，同一时刻只能一个节点服务拥有该锁，当有节点获取锁之后，其他节点无法获取锁，不同节点之间具有互斥性。

超时机制
不考虑异常，正常情况下，请求获取锁之后，处理任务，处理完成之后释放锁。但是如果在处理任务发生服务异常，或者网络异常时，导致锁无法释放。其他请求都无法获取锁，变成死锁。为了防止锁变成死锁，需要设置锁的超时时间。过了超时时间后，锁自动释放，其他请求能正常获取锁。

自动续期
锁设置了超时机制后，如果持有锁的节点处理任务的时候过长超过了超时时间，就会发生线程未处理完任务锁就被释放了，其他线程就能获取到该锁，导致多个节点同时访问共享资源。对此，就需要延长超时时间。开启一个监听线程，定时监听任务，监听任务线程还存活就延长超时时间。当任务完成、或者任务发生异常就不继续延长超时时间。


分布式锁主要有三种实现，数据库、Zookeeper、Redis
Redis 实现分布式锁，是性能最高的，实现方式是两种，一种是利用 Redis 的 SetNX，但是会有死锁问题，所以线上多是用第二种实现也即 Redission 实现分布式锁。

Redisson 是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。Redisson是基于netty通信框架实现的，所以支持非阻塞通信，性能优于Jedis。

Redisson分布式锁四层保护：防死锁、防误删、可重入、自动续期，Redisson 实现 Redis 分布式锁，支持单机和集群模式，

Redis 实现分布式锁的基本原理是什么？
使用 SET key value NX PX timeout 命令：NX 保证只有在键不存在时才能设置成功，PX 设置键的过期时间，以防止死锁的出现。这样可以保证同一时间只有一个客户端能获取到锁。

如何处理分布式锁的可重入性问题？
可重入性问题是指同一个线程在持有锁的情况下可以再次获取锁。为解决这个问题，可以在 Redis 锁的值中记录线程信息，每次加锁时检查并更新计数器。

如果在获取锁之后，业务执行过程中应用程序崩溃，如何保证锁最终被释放？
通过给锁设置过期时间来防止死锁，即使应用程序崩溃，锁也会在过期时间到达后自动释放。另外，可以通过 watchdog 机制定期延长锁的过期时间，确保在业务逻辑长时间运行时锁不会提前释放。

如何优化 Redis 分布式锁的性能？
使用 Lua 脚本进行加锁和释放锁操作，确保这两个操作的原子性。使用 Redisson 库，它提供了高效、健壮的分布式锁实现。

Zookeeper分布式锁性能开销较小，实现复杂度较难，基于Zookeeper的临时节点实现，适用于高可靠性和一致性的分布式锁需求


4、性能监控和分布式追踪整合Skywalking、

在微服务系统中，A 服务调用 B 服务，B 又调用 C 服务，C 又调用 D 服务，会使得链路变得很复杂，一个由客户端发起的请求在后端系统中会经过多个不同的的服务节点调用来协同产生最后的请求结果，每一个前段请求都会形成一条复杂的分布式服务调用链路，链路中的任何一环出现高延时或错误都会引起整个请求最后的失败。
在分布式系统中，必须有人专门做这个事才行，这里用到的是Skywalking

分布式链路追踪原理
假定三个微服务调用的链路如下图所示：Service 1 调用 Service 2，Service 2 调用 Service 3 和 Service 4
那么一条链路追踪会在每个服务调用的时候加上Trace ID 和 Span ID
链路通过TraceId唯一标识，
Span标识发起的请求信息，各span通过parent id 关联起来 (Span:表示调用链路来源，通俗的理解span就是一次请求信息。
一条链路通过Trace Id唯一标识，Span标识发起的请求信息，各span通过parent id 关联起来。

请解释一下 Skywalking 是什么？它在性能监控和分布式追踪中的作用是什么？
Skywalking 是一款开源的 APM（应用性能管理）和分布式追踪系统。它可以帮助我们监控分布式系统的性能，跟踪每个请求的完整链路，识别出性能瓶颈和故障点。

Skywalking相比于zipkin还是有很大的优势的，如下：
skywalking采用字节码增强的技术实现代码无侵入，zipKin代码侵入性比较高
skywalking功能比较丰富，报表统计，UI界面更加人性化
skywalking集成了性能监控和分布式追踪功能，并且支持多种语言的自动探针，适合我们的技术栈。最关键是其对代码的侵入性很小

你是如何利用 Skywalking 实现 PmHub 的性能监控的？能具体描述一下实施过程吗？
我们在 PmHub 中集成了 Skywalking 的探针，通过 Skywalking OAP（后端分析平台）收集和存储数据，并使用 Skywalking UI 进行数据可视化。我们配置了监控的指标，如响应时间、吞吐量和错误率，以全面了解系统的性能状况。

你使用了哪些具体的监控指标来评估 PmHub 的性能？
我们主要监控了响应时间、吞吐量、错误率、调用链和数据库查询时间等指标。这些指标可以帮助我们全面了解系统的运行状态和性能瓶颈。

你能举一个具体的例子，说明通过分布式追踪发现并解决了一个性能问题吗？
例如，我们发现某个请求的响应时间异常长。通过 Skywalking 的调用链分析，我们发现瓶颈在于一个数据库查询。进一步分析发现是因为缺少索引导致的。我们通过优化数据库索引，显著提升了查询性能。

你提到通过该系统使整体响应时间降低了约30%，请具体说明是如何实现这一优化的。
我们通过 Skywalking 识别出性能瓶颈后，进行了一系列优化措施，包括优化数据库查询、改进代码逻辑和增加缓存等。这些措施综合作用，最终使整体响应时间降低了约30%。


5、实现Redis加Lua脚本基于计数器算法的限流

保护高并发服务稳定主要有三大法宝：缓存、降级和限流。

缓存：缓存是一种提高数据读取性能的技术，通过在内存中存储经常访问的数据，可以减少对数据库或其他存储系统的访问，从而提升系统的响应速度。缓存可以应用在多个层面，例如浏览器缓存、CDN 缓存、反向代理缓存和应用缓存等。

降级：在系统压力过大或部分服务不可用时，降级可以暂时关闭一些非核心服务，以保证核心服务的正常运行。降级可以在多个层面进行，例如页面降级、功能降级和服务降级等。

限流：限流是一种控制系统处理请求速率的技术，以防止系统过载。限流可以通过多种算法实现，例如令牌桶算法和漏桶算法等

这三大法宝各有其特点，通常会结合使用，以达到最佳效果。例如，可以通过缓存减少对数据库的访问，通过降级应对系统故障，通过限流防止系统过载。

限流中有两个概念，阈值和拒绝策略

 阈值：
阈值是指在单位时间内允许的最大请求数量。例如，如果将每秒请求数（QPS）限制为500，这意味着系统在1秒内最多只能处理500个请求。通过设置这样的阈值，可以控制系统的负载，防止系统因为处理过多请求而出现问题。 

拒绝策略：
拒绝策略是指当请求数量超过设定的阈值时，系统如何处理这些额外的请求。常见的拒绝策略有： 
直接拒绝：系统立即拒绝超过阈值的请求，不予处理。
排队等待：将超过阈值的请求放入队列，按照一定规则依次处理

常见的限流算法如下：
计数器算法：在固定时间窗口内对请求次数进行计数。如果请求次数超过设定的阈值，就拒绝后续的请求。这个时间窗口可以是1秒、1分钟等。，这就叫“临界点效应”——在窗口边界点处突发大量请求穿透限流机制。

滑动窗口计数器法：将一个大的窗口（如1分钟）划分为多个小窗口（如每10秒），每个小窗口记录请求数，实时滑动更新统计值。这个缓解了临界点效应
漏桶（Leaky Bucket）算法：请求进入漏桶，漏桶以恒定速率出水，当桶满时新的请求被丢弃
令牌桶（Token Bucket）算法：按固定速率生成令牌放入桶中，请求来临时尝试获取令牌才能通过。令牌数未用完可积累（设定最大桶容量）。

目前有两个比较主流的限流方案：
网关层限流。将限流规则应用在所有流量的入口处
中间件限流。将限流信息存储在分布式环境中某个中间件里（比如redis），每个组件都可以从这里获取到当前时间的流量统计，从而决定是否放行还是拒绝。

在整个系统层面，我们采用的是 Gateway 配合 Sentinel 的方式进行限流，但因为登录接口比较特殊，一来会绕过网关认证逻辑，二来容易被刷，所以在登录接口上我们又增加了自定义 Redis+Lua 的限流方式。

Lua脚本：
Lua是一种轻量级、嵌入式脚本语言，经常用于游戏开发、脚本编程和嵌入式系统中。Redis从2.6版本开始支持使用Lua脚本，可以通过EVAL命令执行Lua脚本。使用Lua脚本可以实现原子性操作，避免复杂的多步操作。

在Redis中使用Lua脚本可以带来很多好处：
原子性：Lua脚本在Redis中是原子执行的，这意味着在脚本运行期间不会有其他命令插入执行，保证了操作的原子性。
减少网络开销：通过将多条Redis命令封装在一个Lua脚本中，可以减少客户端与服务器之间的网络通信次数，提高性能。
复杂操作：可以在脚本中实现复杂的逻辑操作，而这些操作在Redis原生命令中可能比较繁琐。


常见使用场景：
分布式锁：利用Lua脚本实现分布式锁，可以确保锁操作的原子性。
计数器限流：使用Lua脚本实现精确的计数器进行限流，避免并发问题。
复杂事务：在Lua脚本中处理多步事务，保证操作的完整性。

您是如何处理并发请求的？在高并发场景下，限流策略是否依然有效？
我们通过Redis单线程的特点和Lua脚本的原子性来处理并发请求，确保计数器的准确性。在高并发场景下，限流策略依然有效，因为Redis的高性能和Lua脚本的原子操作可以应对大量请求。


您是如何处理并发请求的？在高并发场景下，限流策略是否依然有效？
我们使用 Redis + Lua 实现限流，利用 Redis 单线程特性和 Lua 脚本的原子性，确保高并发下操作一致性。限流策略采用滑动窗口或令牌桶算法，Lua 脚本将计数、自增、过期等操作打包执行，避免并发冲突。在高并发场景下，经压测验证，该方案响应快、误差小，限流效果稳定可靠。

6、Sentinel+OpenFeign实现网关流量控制，以及自定义fallback服务降级

微服务架构都是分布式的，由非常多的服务组成。不同的服务之间相互调用，组成了复杂的调用链路。某一个服务的不稳定性会在链路调用中会产生更大更坏的影响。因此我们需要对不稳定的弱依赖服务调用进行熔断降级，在必要的时候切断调用，避免局部不稳定因素导致整个应用的雪崩。熔断降级作为保护自身的手段，通常在调用端进行配置。那如何进行熔断降级呢？Sentinel 就是一个非常不错的选择方案。

Sentinel是什么，它解决了什么问题？
Sentinel是阿里巴巴开源的一个分布式系统的流量管理组件，主要用于保护服务的稳定性。它通过实时监控、熔断降级、限流、系统负载保护等手段，防止由于突发流量或者不稳定的外部依赖导致的服务不可用问题，确保系统的高可用性和稳定性。

Sentinel 的配置默认是放在内存中的，如果服务一旦重启，原先配置好的规则就都不见了,于是使用Nacos 对 Sentinel 进行持久化配置

Sentinel 之所以能够对流量进行控制，是因为它会监控应用的 QPS 流量或者并发线程数等指标，如果达到指定的阈值，就会进行流量控制，避免服务被瞬时的高并发流量击垮，从而保证服务的可靠性。

说说 @SentinelResource 注解
@SentinelResource 是 Sentinel 中一个非常重要的注解，能够帮助我们在代码层面对资源进行保护，结合控制台的规则配置，实现高效的限流与降级策略。通俗点说，就是可以加在接口上，对单个接口做限流、熔断降级等控制。比如说，在 PmHub 的系统服务中，我们就可以为获取用户信息的接口加上 @SentinelResource 注解，blockHandler 参数用于限流，fallback 参数用于降级处理。

什么是 fallback 服务降级
所谓的 fallback 服务降级是指，调用一个服务出现异常时，要给访问者一个比较友好的反馈，比如常见的：“服务繁忙，请稍后再试！”这样就能降低服务的负载，因为异常的情况下，持续不断的请求很容易引发其他服务的崩溃。直接在接口上加 @SentinelResource属于比较粗暴的方式，会导致代码不断膨胀不好统一管理，有没有更优雅的解决方案呢？

OpenFeign 是一个 声明式 HTTP 客户端，用于在 Spring Cloud 微服务架构 中简化服务之间的通信。它提供了一种声明式的方式来定义和调用 HTTP 服务，我们开发者无需手动构建 HTTP 请求，就能轻松实现服务调用。

通过 OpenFeign 来过渡降级处理
对于用户的登录请求，认证服务是不能直接调用系统服务的，因为直接调用不安全嘛，所以 PmHub 抽离出了一个公共包 pmhub-api，把用户接口统一放进去， 认证服务通过 OpenFeign 来调用系统服务，在 pmhub-api 服务中进行统一的服务降级。

讲一下服务降级？
服务降级，说白了就是一种服务托底方案，如果服务无法完成正常的调用流程，就使用默认的托底方案来返回数据。


讲一下服务熔断？
在分布式与微服务系统中，如果下游服务因为访问压力过大导致响应很慢或者一直调用失败时，上游服务为了保证系统的整体可用性，会暂时断开与下游服务的调用连接。这种方式就是熔断。类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示。
服务熔断一般情况下会有三种状态：闭合、开启和半熔断;

闭合状态(保险丝闭合通电OK)：服务一切正常，没有故障时，上游服务调用下游服务时，不会有任何限制。
开启状态(保险丝断开通电Error)：上游服务不再调用下游服务的接口，会直接返回上游服务中预定的方法。
半熔断状态：处于开启状态时，上游服务会根据一定的规则，尝试恢复对下游服务的调用。此时，上游服务会以有限的流量来调用下游服务，同时，会监控调用的成功率。如果成功率达到预期，则进入关闭状态。如果未达到预期，会重新进入开启状态。


讲一下服务隔离？
有点类似于系统的垂直拆分，就按照一定的规则将系统划分成多个服务模块，并且每个服务模块之间是互相独立的，不会存在强依赖的关系。如果某个拆分后的服务发生故障后，能够将故障产生的影响限制在某个具体的服务内，不会向其他服务扩散，自然也就不会对整体服务产生致命的影响。

互联网行业常用的服务隔离方式有：线程池隔离和信号量隔离。


7、分布式事务Seata保证任务审批状态一致性

事务的四大特性（ACID）
1原子性（Atomicity）：
事务中的所有操作要么全部成功，要么全部失败。即使在系统故障的情况下，事务也能保证不会只执行一部分操作。
例子：银行转账操作中，从一个账户扣钱并在另一个账户加钱，这两步操作要么都成功，要么都失败。

2一致性（Consistency）：
事务执行前后，数据库都必须处于一致的状态。所有事务必须使数据库从一个一致状态变换到另一个一致状态。
例子：转账后，两个账户的总金额应该保持不变。

3隔离性（Isolation）：
并发事务之间互不影响，一个事务的中间状态对其他事务不可见。不同事务之间的操作是相互独立的。
例子：同时进行的两个转账操作不会互相干扰，每个操作都看不到对方的中间状态。

4持久性（Durability）：
一旦事务提交，其结果是永久性的，即使系统崩溃，事务的结果也不会丢失。
例子：转账成功后，系统崩溃重启，账户金额的变动依然存在

本地事务解决的是单数据源的数据一致性问题，分布式事务解决的是多数据源数据一致性问题。


分布式事务都有哪些方案？
分布式事务的实现主要有以下 6 种方案：
XA 方案
TCC 方案
SAGA 方案
本地消息表
可靠消息最终一致性方案
最大努力通知方案


Seata 是什么
Seata 是一款阿里开源的分布式事务解决方案，是一种简单可扩展自治的事务框架
有了 Seata，我们只需要在需要使用分布式事务的地方加上 @GlobalTransactional 注解即可。
Seata 支持 3 种模式，AT 模式、TCC 模式、Saga 模式


AT 模式
自动补偿事务，通过代理自动管理事务的提交和回滚，适合简单场景
易于使用，开发成本低，自动管理事务
依赖于数据库支持，适合简单场景，不适合复杂业务逻辑
简单的业务场景，如单表操作、小型微服务

TCC 模式
Try-Confirm-Cancel，开发者手动实现业务逻辑的 Try、Confirm 和 Cancel 三个阶段，确保事务的一致性
提供强一致性，适用于需要严格事务管理的场景
实现复杂，开发成本高，需要手动管理事务的各个阶段
对一致性要求高且业务操作较短的场景，如支付、交易等涉及资金的系统

Saga 模式
长事务模式，通过一系列的子事务来完成主事务，子事务之间独立运行，如果某个子事务失败，则通过补偿事务进行回滚
无需全局锁，高性能，适用于长事务场景
需要开发补偿逻辑，可能无法保证强一致性

8、整合Rocketmq实现审批流消息推送
在分布式微服务系统中，消息队列在系统中扮演者很重要的角色，主要有解耦、异步处理、削峰等作用。
Kafka、ActiveMQ、RabbitMQ、RocketMQ 区别

如果是大数据领域的实时计算、日志采集等场景，就用 kafka
对时效性有要求，且不关心底层情况，用 RabbitMQ 就可以
国内的大部分项目，特别是微服务项目，就用阿里的 RocketMQ 就好了，有丰富的教程且是阿里出品，经历过双十一这种大促，肯定是没问题的。所以 PmHub 也选择了 RocketMQ。

你们的项目为什么要用消息队列？为何选RocketMQ？
主要是为了系统解耦提高系统健壮性和稳定性，及异步提高系统响应。

如何保证消息队列的高可用
这道题需要对几个 MQ 有比较深入的理解，比如 RabbitMQ 的镜像集群模式模式保证高可用，以及 kafka 和 rocketmq 天然支持的高可用架构的原理需要掌握好。

如何保证消息的幂等性
所谓消息的幂等性就是如何保证消息不被重复消费，我们说 MQ 中装的是很多的消息，那重复消费就是必须直面的问题。
如果问的是整个消息队列的场景，kafka 是有 offset 来幂等控制，其他的消息队列保证幂等都是通过业务开发自己来保证的， rocketmq，如何保证消息不被重复消费，其实是业务场景控制的。在消费测，会将任务的 taskId 和 Assignee 一同写入 redis，每次消费会先去 redis 中查询当前同一个消息是否已被消费过了，如果没被消费国，才执行消费逻辑，这样能有效避免同一个消息通知发送多次问题，也即保证了幂等性



如何解决消息队列的延时以及过期失效问题
比如在 RocketMQ 中是可以设置过期时间的，也就是 TTL（这个时间可以通过配置 fileReservedTime 参数进行设置，单位是小时。默认值是 72 小时（3 天））。
如果消息在 queue 中积压超过一定的时间就会被 RocketMQ 给清理掉，这个数据就没了。这种情况只能批量查出丢失的消息，手动发到 mq 去补一次这些过期的消息了。

如何解决消息堆积问题
在 rocketmq 中，发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢弃不重要的消息。可以使用重置位点功能直接调整消费位点到指定时刻或者指定位置。

RocketMQ 如何保证高性能读写
主要 2 种方式：
传统 IO 方式
零拷贝技术



9、保证缓存和数据库的一致性

对于开发来说本地缓存常用有以下这些：JDK 自带的 HashMap 和 ConcurrentHashMap
Ehcache、Guava Cache、Spring Cache、Caffeine 等常见的本地缓存框架

除了本地缓存，还有常见的分布式缓存如常用的 Redis。本地缓存和分布式缓存很好区别，本地缓存和应用在同一个地方，而分布式缓存是可以独立部署在不同的服务器上的，比如 Redis 可以单机或者集群部署在不同的服务器上。不管是本地缓存还是分布式缓存，都只有一个目的，那就是用空间换时间，用更多的存储空间来存储一些可能重复使用或计算的数据，从而减少数据的重新获取或计算的时间。



缓存一致性问题
你有没有想过一个问题，既然一份数据同时在缓存中和数据库中都有，那这两者到底哪个是最新数据呢？如何保证其数据一致性呢？

那么导致不一致的原因主要有：
缓存过期：缓存中的数据有一个生命周期，当数据过期后，如果没有及时更新，就会出现不一致的情况。
写操作延迟：在执行写操作时，数据库更新和缓存更新的时间不同步，可能会导致缓存中的数据不一致。
并发操作：多个并发操作同时进行，可能会导致数据更新时出现竞态条件，从而导致缓存和数据库数据不一致。
缓存失效策略不当：使用不当的缓存失效策略，可能导致缓存中的数据无法及时更新，导致不一致。
网络延迟或故障：由于网络延迟或故障，缓存服务器和数据库之间的通信出现问题，导致数据不一致。


常见的解决不一致问题有如下解决方案：
Cache Aside 模式：在读写操作中使用 Cache Aside 模式，确保在写操作后及时失效缓存中的数据。
分布式锁：在并发写操作时使用分布式锁，确保同时只有一个操作能够更新缓存和数据库，避免竞态条件。
双写一致性：在写操作时同时更新数据库和缓存，确保数据的一致性。
延迟双删：在写操作时，先删除缓存中的数据，更新数据库后，再次删除缓存中的数据，确保缓存中数据的一致性。
版本控制：在缓存和数据库中使用版本号或时间戳，确保数据更新时的一致性检查。
监控和告警：对缓存和数据库中的数据进行监控，发现不一致时及时告警并处理。


为什么你删除缓存，而不更新缓存呢？
主要原因有 2 点：
1、更新缓存浪费服务器资源：频繁的缓存更新可能导致缓存服务器的负载增加，通过删除缓存而不是频繁更新，可以减少缓存服务器的压力，提高系统整体性能。
2、避免脏读：在高并发环境下，如果在写操作时直接更新缓存，可能会导致并发读操作获取到未完全更新的数据，从而产生脏读现象。删除缓存可以避免这种情况，因为在缓存被删除后，所有读操作都会直接从数据库读取最新数据。
3、减少并发冲突：如果在写操作时直接更新缓存，可能会引发大量的并发冲突，特别是在频繁写操作的情况下。通过删除缓存，可以减少并发冲突的可能性，简化并发控制。
4、避免双写问题：在写操作时同时更新数据库和缓存，可能会导致双写不一致的问题。如果在更新数据库后失败了，缓存和数据库数据可能不同步。删除缓存可以避免这种双写问题，只需保证数据库写入成功。

先更新 DB，再删除缓存就是完美解决方案了吗？
并发读写导致缓存脏数据
优化策略如下：
延迟双删、先删缓存，再异步串行更新数据库、加分布式锁



